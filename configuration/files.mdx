---
title: "Files"
description: "Choose between Cloudfalre R2, AWS S3, Google Cloud Storage, or Azure Blob Storage"
icon: "files"
---

## Implementations

The main logic can be found in the `service-go-user/domain/file/provider.go` file.

The local provider stores files in a local folder, while the other providers store files in their respective cloud storage services.

## Configuration

This choice can be made using the **GoFast CLI** or by modifying the `docker-compose.yml` file.

### via CLI

Possible options are `Cloudflare R2`, `AWS S3`, `Google Cloud Storage`, `Azure Blob Storage` and `Local (folder)`.

### via Docker Compose

Possible options are `r2`, `s3`, `gcs`, `azblobl` and `local`.

### Files Configuration

Depending on the provider, you need to set the following environment variables in the `docker-compose.yml` file:

- for `r2`, set `R2_ENDPOINT`, `R2_ACCESS_KEY`, and `R2_SECRET_KEY`.
- for `s3`, set `S3_REGION`, `S3_ACCESS_KEY`, and `S3_SECRET_KEY`.
- for `gcs`, set `GOOGLE_APPLICATION_CREDENTIALS`.
- for `azblob`, set `AZBLOB_ACCOUNT_NAME` and `AZBLOB_ACCOUNT_KEY`.
- for `local`, set `FILE_DIR`.

```yaml
services:
  server:
    environment:
      FILE_PROVIDER: r2
      BUCKET_NAME: ${BUCKET_NAME}
      R2_ENDPOINT: ${R2_ENDPOINT}
      R2_ACCESS_KEY: ${R2_ACCESS_KEY}
      R2_SECRET_KEY: ${R2_SECRET_KEY}
      # FILE_PROVIDER: s3
      # S3_REGION: ${S3_REGION}
      # S3_ACCESS_KEY: ${S3_ACCESS_KEY}
      # S3_SECRET_KEY: ${S3_SECRET_KEY}
      # FILE_PROVIDER: gcs
      # GOOGLE_APPLICATION_CREDENTIALS: ${GOOGLE_APPLICATION_CREDENTIALS}
      # FILE_PROVIDER: azblob
      # AZBLOB_ACCOUNT_NAME: ${AZBLOB_ACCOUNT_NAME}
      # AZBLOB_ACCOUNT_KEY: ${AZBLOB_ACCOUNT_KEY}
      # FILE_PROVIDER: local
      # FILE_DIR: ${FILE_DIR}
```
## Getting Secrets

### Cloudflare R2

1. Go to [Cloudflare R2](https://www.cloudflare.com/r2/) and create an account.
2. Create a new bucket
3. On `R2` dashboard, click on `Manage R2 API Tokens` and create a new token.
4. Set the `R2_ENDPOINT`, `R2_ACCESS_KEY`, and `R2_SECRET_KEY` in the `docker-compose.yml` file.

### AWS S3

1. Go to the [AWS Console](https://aws.amazon.com/console/) and create an account.
2. Go to the [S3](https://s3.console.aws.amazon.com/s3/home) dashboard.
3. Create a new bucket.
4. Go to the [IAM](https://console.aws.amazon.com/iam/home) dashboard.
5. Create a new user with `AmazonS3FullAccess` policy.
6. Set the `S3_REGION`, `S3_ACCESS_KEY`, and `S3_SECRET_KEY` in the `docker-compose.yml` file.

### Google Cloud Storage

1. Go to the [Google Cloud Console](https://console.cloud.google.com/) and create an account.
2. Create a new project.
3. Go to the [Storage](https://console.cloud.google.com/storage) dashboard.
4. Create a new bucket.
5. Go to the [IAM & Admin](https://console.cloud.google.com/iam-admin) dashboard.
6. Create a new service account with `Storage Admin` role.
7. Download the JSON key and set the `GOOGLE_APPLICATION_CREDENTIALS` in the `docker-compose.yml` file.

### Azure Blob Storage

1. Go to the [Azure Portal](https://portal.azure.com/) and create an account.
2. Create a new storage account.
3. Go to the storage account and create a new container.
4. Go to the `Access keys` section and copy the `Connection string`.
5. Set the `AZBLOB_ACCOUNT_NAME` and `AZBLOB_ACCOUNT_KEY` in the `docker-compose.yml` file.

## Need help?

Visit our discord server to ask any questions, make suggestions and give feedback :).

https://discord.gg/EdSZbQbRyJ
